{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b598157a04a74bcda1e52a240d06399c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07eced1a774b438da179bed801638e48",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b792004ab754fa5a02fa96f2fa16162",
              "IPY_MODEL_0dec6cd1697a4f9ba4aba0ff3fd11093"
            ]
          }
        },
        "07eced1a774b438da179bed801638e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b792004ab754fa5a02fa96f2fa16162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da7a1d7cce804e29906d3d4757b0b9f3",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a61bab9d35e247d6be4c77ae6adca33c"
          }
        },
        "0dec6cd1697a4f9ba4aba0ff3fd11093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80d1ded3744b42b2894ce1962b2c93a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [05:06&lt;00:00, 306.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8070eb7ac493436d9719a544b9ce41a2"
          }
        },
        "da7a1d7cce804e29906d3d4757b0b9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a61bab9d35e247d6be4c77ae6adca33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80d1ded3744b42b2894ce1962b2c93a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8070eb7ac493436d9719a544b9ce41a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6a41ae6af234de4b96bad725e0f6db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59655e281b8c4f3181c8e6c26015e202",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a607a55e6f7140ffa00053ee5b33bd91",
              "IPY_MODEL_a1299c48e2df4a68b0d9470f2d7595a6"
            ]
          }
        },
        "59655e281b8c4f3181c8e6c26015e202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a607a55e6f7140ffa00053ee5b33bd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc36c38d37fe4bc2acf626e5284fc4d5",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 190,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 190,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25b6f0f2f3ad4adfbc76c0c97bd21b75"
          }
        },
        "a1299c48e2df4a68b0d9470f2d7595a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96be4784928242cea94fbef3f43c605c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 190/190 [05:06&lt;00:00,  1.61s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d3e656adef04df682a36d4afb9e3ee4"
          }
        },
        "dc36c38d37fe4bc2acf626e5284fc4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25b6f0f2f3ad4adfbc76c0c97bd21b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96be4784928242cea94fbef3f43c605c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d3e656adef04df682a36d4afb9e3ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhho580828/github-pages/blob/main/Adding_Custom_Vocabulary_and_Continuing_Training_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szQR4KwiOEOj"
      },
      "source": [
        "# Adding Custom Vocabulary and Continuing Training\n",
        "\n",
        "*by Nick Ryan*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXKyKe3NZONV"
      },
      "source": [
        "# S1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgITqyZXZRA7"
      },
      "source": [
        "Many NLP applications are about classifying text in very specific and unique domains. Whether you're building a sentiment classifier for an auto parts company or a chatbot for your financial services customers,  sometimes a model like BERT doesn't quite cut it because certain unique and unusual names, phrases, and terms are such a key part of your data. \n",
        "\n",
        "In this tutorial we will discuss how to customize a language model like BERT for your own text domain and show you how to:\n",
        "\n",
        "- Add new words to the model vocabulary\n",
        "- Create custom embeddings for those new words\n",
        "- Continue training the model with your own dataset\n",
        "- Run a quick test to see the progress of your continued training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVa5S9z0OIjf"
      },
      "source": [
        "## Notebook Access"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCFXYdbIXguc"
      },
      "source": [
        "\n",
        "-------------------------------------\n",
        "\n",
        "[![Notebook Access](https://drive.google.com/uc?export=view&id=1yPJapK5X9kXLDhtuDJm3Hw4-ZlxMwcsa)](https://www.chrismccormick.ai/membership)\n",
        "\n",
        "<sup>\\*</sup>Notify me [here](team@chrismccormick.ai)\n",
        "\n",
        "<sup>\\*\\*</sup>Join my site [here](https://www.chrismccormick.ai/membership) \n",
        "\n",
        "---------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC3O1ViohOCK"
      },
      "source": [
        "## 1.1 Background and Problem Statement\n",
        "\n",
        "\n",
        "**Why Not Just Fine-Tune?**\n",
        "\n",
        "The most common method for building a text model on top of BERT has been to use the pretrained BERT model as a basis for fine-tuning a classifier on your specific application. However, sometimes your application uses text and terminology from a specific domain that is not reflected in the training corpus used by BERT, SciBERt, BioBERT or other variants, resulting in vocabulary and weights poorly suited to your application. \n",
        "\n",
        "For example, say you work in the automotive industry and want to build an NLP application revolving around automotive brands and the mention of your new company named \"carz4friendz.\" You could fine-tune your model on top of a pretrained BERT model, but because BERT was trained on a limited amount of technical automotive data it will have a poor \"understanding\" of automative brands, parts, technical terminiology, and will not have an understanding or efficient tokenization of your new company name, which is a critical part of the application. \n",
        "\n",
        "**Customizing Vocabulary and \"Intermediate\" Training**\n",
        "\n",
        "In this case there are two things you can do to help give your NLP application a boost:\n",
        "\n",
        "1.  Add new terms to the model vocabulary that are particularly important for your application. In our example, we would add the name of our automative company \"carz4friendz\" to BERT's vocabulary.\n",
        "2.  Continue pretraining the model or fine-tuning the model on an \"intermediate\" task focused on text data that is relevant to your final application. In our example, we would continue pretraining BERT on news articles, industry reports, and text from the automotive industry to help improve the model's performance when it comes to automotive text.\n",
        "\n",
        "![Intermediate Pre-Training](https://drive.google.com/uc?export=view&id=1TLvg8OXUDugyZo2_cVsWElzbuKuUzi9O)\n",
        "\n",
        "**Applying this Approach to COVID-19**\n",
        "\n",
        "In this tutorial, we'll apply these two solutions to an application everyone is familiar with: COVID-19. SciBERT was trained largely on a biomedical corpus so is a good candidate base for coronavirus-related NLP applications if we want to search, index, cluster, etc. coronavirus research publications. However, SciBERT was trained in early 2019, so the model was never trained on coronavirus research, nor does it even have a vocabulary entry for some of the key terms we would need for our application like \"coronavirus,\" \"COVID-19\", \"COVID\", etc.\n",
        "\n",
        "We will first update the SciBERT vocabulary and show you how to add relevant vocabulary to your tokenizer and model. Then we will show you how to continue training your model with a custom dataset. Specifically, we will show you how to continue the masked language modeling task used for pretraining, a task that we have not previously explored in our tutorials and one that is very simple to execute (all you need is unlabeled data!).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clB4Bklb-B13"
      },
      "source": [
        "# S2. Import SciBERT Community Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3dpoWs_Dn-t"
      },
      "source": [
        "\n",
        "First we'll use SciBERT, a popular BERT variant (it has over 28,000 downloads in the past month on huggingface!). This is well suited to our task because our target domain is biomedical text.\n",
        "\n",
        "* SciBERT was trained on scientific literature--1.14M papers.\n",
        "  * Roughly 1/5th of the papers are from \"the computer science domain\", and the remaining 4/5ths from \"the broad biomedical domain\".\n",
        "* SciBERT was created by the Allen Institute of AI (a highly respected group in NLP, if you're unfamiliar).\n",
        "* Their paper was first submitted to arXiv in March, 2019 [here](https://arxiv.org/abs/1903.10676). They uploaded their implementation to GitHub [here](https://github.com/allenai/scibert) around the same time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJF_caESC0yS"
      },
      "source": [
        "SciBERT is available from the [huggingface community models](https://huggingface.co/models). If you're interested in a BERT variant from the community models in the transformers library, importing can be incredibly simple. Most community models include instructions on the download page for importing and usage. \n",
        "\n",
        "To import SciBERT all we need to do is provide the appropriate path to the SciBERT model we're interested in. After that, the model and tokenizer interface and methods follow the regular huggingface interface and methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN2Ms9W3IKrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "a4c4d8a6-610e-4510-ab8e-b37a56f44365"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZjLyp8Vwm8j"
      },
      "source": [
        "We'll import BertForMaskedLM, the masked language modeling (MLM) variant for BERT. Simply, this is the BERT model with a masked language modeling head on top allowing us to continue the training procedure used to generate BERT and SciBERT. \n",
        "\n",
        "This does not include the next sentence prediction (NSP) task, which can be found under the BertForPreTraining class that includes both a NSP head and a MLM head. You are welcome to use this class or any of the other pretraining tasks used by BERT-like models, but based on the findings of papers like ROBERTA and T5, it doesn't appear that the NSP task in particular contributes much to the final model performance, so we forego it here for simplicity's sake."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar2WGznUIKpq"
      },
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, BertForPreTraining, BertConfig\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scibert_tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\", do_lower_case=True)\n",
        "scibert_maskedlm_model = BertForMaskedLM.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWbwS46uOWf4"
      },
      "source": [
        "# S3. Adding to the Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSGCLOfJSrYR"
      },
      "source": [
        "## 3.1 Add a Token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQs1xM7tSPj5"
      },
      "source": [
        "Let's say that, for BERT or any of its variants, we'd like to add new vocabulary into the model. In this example, we're interested in organizing, searching, or indexing some scientific literature related to COVID-19. We want to continue training SciBERT on new batches of COVID-19 literature so that we can organize new and old research related to COVID-19.\n",
        "\n",
        "Since SciBERT was trained before the outbreak of COVID-19, this word likely isn't in the vocabulary. In fact, we can confirm it is not:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "假設對於 BERT 或其任何變體，我們想向模型中添加新詞彙。 在此示例中，我們有興趣組織、搜索或索引一些與 COVID-19 相關的科學文獻。 我們希望繼續使用新批次的 COVID-19 文獻對 SciBERT 進行訓練，以便我們可以組織與 COVID-19 相關的新舊研究。\n",
        "\n",
        "由於 SciBERT 在 COVID-19 爆發之前接受過訓練，因此這個詞可能不在詞彙表中。 事實上，我們可以確認它不是："
      ],
      "metadata": {
        "id": "dPm-VTAiAbke"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5knK645Tpep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11961e4d-c524-4754-bc01-e231260dc69c"
      },
      "source": [
        "'covid' in scibert_tokenizer.vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDeXRriPTuP7"
      },
      "source": [
        "While any word can be constructed out of constituent subwords, for example..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "雖然任何單詞都可以由子詞組合而構成，例如......"
      ],
      "metadata": {
        "id": "PGI1-qX_BLev"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYxOYgM-S41n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46b538f1-25fe-481c-f735-ec11290009a8"
      },
      "source": [
        "scibert_tokenizer.tokenize(\"covid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cov', '##id']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVaqRbdnS_Ac"
      },
      "source": [
        "...words like \"covid\" and \"coronavirus\" will be quite important for our research, so it is perhaps worth going out of our way to teach the model new vocabulary in hopes that it improves our results downstream.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...像“covid”和“coronavirus”這樣的詞對我們的研究來說非常重要，所以我們或許值得不遺餘力地教模型新詞彙，希望它能改善我們下游的結果。"
      ],
      "metadata": {
        "id": "dApndyAtCDf3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUJttRZlsa9l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ea281cc-31cc-4d1c-c37f-2f8c335a8d7a"
      },
      "source": [
        "test_sentence = \"COVID-19, COVID, coronavirus.\"\n",
        "scibert_tokenizer.tokenize(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cov', '##id', '-', '19', ',', 'cov', '##id', ',', 'corona', '##virus', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLTGw7Y0sQ86"
      },
      "source": [
        "None of these key terms are in the SciBERT vocabulary. Fortunately huggingface provides an interface to add to the tokenizer's vocabulary. We will just add a single token, \"covid\", to demonstrate the addition of new terms to the model, but you are able to add as many terms as you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96pXIsJHU0zq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4ed6a0d-0c26-4405-dfd2-a1f37a71404f"
      },
      "source": [
        "print (len(scibert_tokenizer)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OJv-j7_U0rF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc2f482e-843e-439f-9d7a-cc619749b353"
      },
      "source": [
        "scibert_tokenizer.add_tokens([\"covid\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWB5KopHU0kt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "166c9df1-cba8-4d27-ce25-7b16a834da5f"
      },
      "source": [
        "print (len(scibert_tokenizer)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLJjJjfnsk6w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "733f8f8d-cc24-4ded-cbc3-d044e3a664fc"
      },
      "source": [
        "test_sentence = \"COVID-19, COVID, coronavirus.\"\n",
        "scibert_tokenizer.tokenize(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['covid', '-', '19', ',', 'covid', ',', 'corona', '##virus', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDygWV2p0YWr"
      },
      "source": [
        "Cool! \"covid\" is now part of the tokenizer vocabulary.\n",
        "\n",
        "Now that the tokenizer is updated, we need to update the input embeddings of our model. We added one term to the tokenizer vocabulary so we need to add one new vector to the input embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNHgxSlbVhNF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7023939f-7ca8-4b41-fd15-7404bc4429af"
      },
      "source": [
        "# Add a new randomly initialized vector to the end of the embeddings matrix\n",
        "scibert_maskedlm_model.resize_token_embeddings(len(scibert_tokenizer)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(31091, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QC1f52tNAsv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5b26b4f-8746-473a-9248-d7cdc09750ec"
      },
      "source": [
        "# New radom embedding vector\n",
        "print (scibert_maskedlm_model.get_input_embeddings().weight[-1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de3lRFVuPbiq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9021c2f4-82d1-4433-94b2-0c1d3ca1e316"
      },
      "source": [
        "random_vector = scibert_maskedlm_model.get_input_embeddings().weight[-1].detach().numpy()\n",
        "\n",
        "plt.title(\"Randomly Initialized Vector\")\n",
        "plt.hist(random_vector, bins=50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3NLAtfNUYSb"
      },
      "source": [
        "## 3.2 Create A Custom Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K5_isAz1bCF"
      },
      "source": [
        "Great! We have a new embedding vector.\n",
        "\n",
        "There's a slight problem: this new \"covid\" vector is completely random while the rest of our input embeddings have been thoroughly trained. Our goal is to continue pretraining the model to update all weights in general, but also to achieve a good embedding for our new vocabulary term.\n",
        "\n",
        "One possible workaround is to change the random embedding to something else. Instead of initializing as a random vector, we can perhaps speed up the process by initializing \"covid\" with an embedding slightly closer to its meaning. In this example, the embedding for \"virus\" is probably a good place to start, but it's possible to combine the embeddings of multiple words into an embedding we think might best approximate the meaning of our new term. We'll combine the embedding for \"virus\" with the embedding for \"respiratory\" by taking the mean, but of course you can combine any number of terms in any way you think might best approximate your new vocabulary term's meaning.\n",
        "\n",
        "Note that this idea is experimental and application-dependent, but it's probably more efficient than training on a random initialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "419-miHjAFlL"
      },
      "source": [
        "# Get the index of these terms in our vocabulary\n",
        "virus_id = scibert_tokenizer.convert_tokens_to_ids(\"virus\")\n",
        "respiratory_id = scibert_tokenizer.convert_tokens_to_ids(\"respiratory\")\n",
        "\n",
        "# Get the embeddings for these terms\n",
        "virus_embedding = scibert_maskedlm_model.get_input_embeddings().weight[virus_id]\n",
        "respiratory_embedding = scibert_maskedlm_model.get_input_embeddings().weight[respiratory_id]\n",
        "\n",
        "# Take the mean of these embeddings\n",
        "mean_embedding = torch.mean(torch.stack([virus_embedding, respiratory_embedding]), dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKfLYlLaCsIp"
      },
      "source": [
        "# Replace our randomly initialized embedding vector with our mean embedding vector\n",
        "# Make sure to replace the .data of the weights and not the weights themselves to preserve the compute graph \n",
        "scibert_maskedlm_model.get_input_embeddings().weight[-1].data[:] = mean_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P37ais0n3ycW"
      },
      "source": [
        "Let's take a look at the new mean embedding vector of \"covid\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPaurTi8NNQ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "55d3da68-bdc3-4fa9-c383-f2d60e91bcb7"
      },
      "source": [
        "mean_vector = scibert_maskedlm_model.get_input_embeddings().weight[-1].detach().numpy()\n",
        "\n",
        "plt.title(\"Custom Initialized Vector\")\n",
        "plt.hist(mean_vector, bins=50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4FAkuIf4DUE"
      },
      "source": [
        "As we can see, this is different from the randomly initialized vector we had before, so the update was successful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuQrWxu_Gpzn"
      },
      "source": [
        "Let's make a copy of our untrained SciBERT model to use for comparison later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7xzyQuCF1xI"
      },
      "source": [
        "import copy\n",
        "\n",
        "untrained_scibert_model_with_custom_embedding = copy.deepcopy(scibert_maskedlm_model)\n",
        "untrained_scibert_tokenizer_with_custom_embedding = copy.deepcopy(scibert_tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh3ouF7NXATL"
      },
      "source": [
        "# S4. Continue Pretraining the Model\n",
        "\n",
        "Now, with our updated vocabulary let's continue to train SciBERT on COVID-19 literature to improve downstream model performance on COVID-19 related NLP tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tF-FQ1JUiAu"
      },
      "source": [
        "## 4.1 Getting our Dataset Ready"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeA1g4LT4aG0"
      },
      "source": [
        "The [CORD-19](https://allenai.org/data/cord-19) dataset from Allen AI is large collection of COVID-19 related text and numerical data. This data has been used by the data science community to produce insights and analysis to further progress COVID-19 research and care. If this interests you, check out Kaggle for a ton of great user-submitted analyses and focused research questions that the medical community is trying to answer.\n",
        "\n",
        "The CORD-19 dataset is, however, very large and requires preprocessing, so for our purposes of demonstrating pretraining we will use a smaller subset of coronavirus research. [This dataset](https://www.kaggle.com/phiitm/covid19-research-preprint-data) made by Pranav Hari contains several thousand rows of data on COVID-19 research papers, including the abstract for each paper. This is the text that we will use for continuing pretraining. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr8Dk-F87LQ7"
      },
      "source": [
        "We've added the dataset to Google Drive beforehand and can now download the dataset using the unique Drive ID:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMl5gBz_9bfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "abb68780-91bf-48cc-e79f-3ce1f2a3c810"
      },
      "source": [
        "import gdown\n",
        "\n",
        "print('Downloading data...')\n",
        "\n",
        "# Specify the name to give the file locally. \n",
        "output = 'abstracts.csv'\n",
        "    \n",
        "# Specify the Google Drive ID of the file.\n",
        "file_id = '1bv_iRnYyfbOA5OfGqR_shYHFuARkPZRT'\n",
        "    \n",
        "# Download the file.\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, \n",
        "                quiet=False)\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bv_iRnYyfbOA5OfGqR_shYHFuARkPZRT\n",
            "To: /content/abstracts.csv\n",
            "11.8MB [00:00, 238MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmZMLBk-z5FC"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('abstracts.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdEnm0j_7ddQ"
      },
      "source": [
        "Let's take a quick look at the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX1WyRUfjWV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "outputId": "87fd3ee1-0d4d-41a5-c2aa-e9e2c4e4a11e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOI</th>\n",
              "      <th>Date of Upload</th>\n",
              "      <th>Title of preprint</th>\n",
              "      <th>Preprint Link</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Number of Authors</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s) Institutions</th>\n",
              "      <th>Uploaded Site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.1101/2020.06.19.20135996</td>\n",
              "      <td>2020-06-20</td>\n",
              "      <td>The support needs of Australian primary health...</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.06.1...</td>\n",
              "      <td>Aim: To identify Australian primary healthcare...</td>\n",
              "      <td>7</td>\n",
              "      <td>['Elizabeth Halcomb', 'Anna Williams', 'Christ...</td>\n",
              "      <td>{\"University of Wollongong\": 6, \"University of...</td>\n",
              "      <td>medrxiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.1101/2020.06.18.20135103</td>\n",
              "      <td>2020-06-20</td>\n",
              "      <td>Modeling quantitative traits for COVID-19 case...</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.06.1...</td>\n",
              "      <td>Medical practitioners record the condition sta...</td>\n",
              "      <td>6</td>\n",
              "      <td>['Nuria Queralt-Rosinach', 'Susan Bello', 'Rob...</td>\n",
              "      <td>{\"Leids Universitair Medisch Centrum\": 1, \"The...</td>\n",
              "      <td>medrxiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.1101/2020.06.19.20135905</td>\n",
              "      <td>2020-06-20</td>\n",
              "      <td>SARS-CoV-2 RT-PCR profile in 298 Indian COVID-...</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.06.1...</td>\n",
              "      <td>Background: Despite being in the 5th month of ...</td>\n",
              "      <td>9</td>\n",
              "      <td>['bisakh bhattacharya', 'Rohit Kumar', 'Dr. Ve...</td>\n",
              "      <td>{\"AIIMS, New Delhi\": 8, \"All India Institute o...</td>\n",
              "      <td>medrxiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.1101/2020.06.19.20135491</td>\n",
              "      <td>2020-06-20</td>\n",
              "      <td>Inhaled corticosteroid use and risk COVID-19 r...</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.06.1...</td>\n",
              "      <td>Background: Early descriptions of the coronavi...</td>\n",
              "      <td>33</td>\n",
              "      <td>['- The OpenSAFELY Collaborative', 'Anna Schul...</td>\n",
              "      <td>{\"\": 1, \"London School of Hygiene and Tropical...</td>\n",
              "      <td>medrxiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.1101/2020.06.19.20135533</td>\n",
              "      <td>2020-06-20</td>\n",
              "      <td>The immediate psychological response of the ge...</td>\n",
              "      <td>http://medrxiv.org/cgi/content/short/2020.06.1...</td>\n",
              "      <td>Background: The health and economic burden pan...</td>\n",
              "      <td>4</td>\n",
              "      <td>['Royes Joseph', 'Dhfer Alshayban', 'Jisha M L...</td>\n",
              "      <td>{\"College of Clinical Pharmacy, Imam Abdulrahm...</td>\n",
              "      <td>medrxiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           DOI  ... Uploaded Site\n",
              "0  10.1101/2020.06.19.20135996  ...       medrxiv\n",
              "1  10.1101/2020.06.18.20135103  ...       medrxiv\n",
              "2  10.1101/2020.06.19.20135905  ...       medrxiv\n",
              "3  10.1101/2020.06.19.20135491  ...       medrxiv\n",
              "4  10.1101/2020.06.19.20135533  ...       medrxiv\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAKBGaxY7gqS"
      },
      "source": [
        "What we're really interested in is text data for pretraining, so we'll use the abstracts from these research papers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKbMh_iwj2nh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c443e3ba-ceb2-4069-ac60-d0fe79819955"
      },
      "source": [
        "# Examples of our abstracts\n",
        "df.Abstract.values[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Aim: To identify Australian primary healthcare nurses immediate support needs during the COVID-19 pandemic. Background: COVID-19 has had widespread implications for primary healthcare nurses. Supporting these nurses' capacity to deliver quality care ensures that ongoing health needs can be met. Methods: Primary healthcare nurses were recruited to an online survey via social media and professional organisations in April 2020. Results: Six-hundred and thirty-seven responses were included in analysis. Participants provided 1213 statements about perceived supports required to provide quality clinical care. From these, seven key categories emerged, namely; personal protective equipment, communication, funding, industrial issues, self-care, workplace factors and valuing nurses. Conclusion: A number of key issues relating to personal health and safety, care quality, and job security need to be addressed to support primary healthcare nurses during the COVID-19 pandemic. Addressing these support issues can assist in retaining nurses and optimising the role of primary healthcare nurses during a pandemic. Implications for nursing management: Responding to the needs of primary healthcare nurses has the potential to facilitate their role in providing community-based healthcare. This knowledge can guide the provision of support for primary healthcare nurses during the current pandemic, as well as informing planning for future health crises.\",\n",
              "       'Medical practitioners record the condition status of a patient through qualitative and quantitative observations. The measurement of vital signs and molecular parameters in the clinics gives a complementary description of abnormal phenotypes associated with the progression of a disease. The Clinical Measurement Ontology (CMO) is used to standardize annotations of these measurable traits. However, researchers have no way to describe how these quantitative traits relate to phenotype concepts in a machine-readable manner. Using the WHO clinical case report form standard for the COVID-19 pandemic, we modeled quantitative traits and developed OWL axioms to formally relate clinical measurement terms with anatomical, biomolecular entities and phenotypes annotated with the Uber-anatomy ontology (Uberon), Chemical Entities of Biological Interest (ChEBI) and the Phenotype and Trait Ontology (PATO) biomedical ontologies. The formal description of these relations allows interoperability between clinical and biological descriptions, and facilitates automated reasoning for analysis of patterns over quantitative and qualitative biomedical observations.',\n",
              "       'Background: Despite being in the 5th month of pandemic, knowledge with respect to viral dynamics, infectivity and RT-PCR positivity continues to evolve. Aim: To analyse the SARS CoV-2 nucleic acid RT-PCR profiles in COVID-19 patients. Design: It was a retrospective, observational study conducted at COVID facilities under AIIMS, New Delhi. Methods : Patients admitted with laboratory confirmed COVID-19 were eligible for enrolment. Patients with incomplete details, or only single PCR tests were excluded. Data regarding demographic details, comorbidities, treatment received and results of SARS-CoV-2 RT-PCR performed on nasopharyngeal and oropharyngeal swabs, collected at different time points, was retrieved from the hospital records. Results : 298 patients were included, majority were males (75.8%) with mean age of 39.07 years (0.6-88 years). The mean duration from symptom onset to first positive RT-PCR was 4.7 days (SD 3.67), while that of symptom onset to last positive test was 17.83 days (SD 6.22). Proportions of positive RT-PCR tests were 100%, 49%, 24%, 8.7% and 20.6% in the 1st, 2nd, 3rd, 4th & >4 weeks of illness. 12 symptomatic patients had prolonged positive test results even after 3 weeks of symptom onset. Age >= 60 years was associated with prolonged RT-PCR positivity (statistically significant). Conclusion : This study showed that the average period of PCR positivity is more than 2 weeks in COVID-19 patients; elderly patients have prolonged duration of RT-PCR positivity and requires further follow up.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvslNHmT-xi2"
      },
      "source": [
        "abstracts = df.Abstract.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7fEkhvv7tO2"
      },
      "source": [
        "Next, we'll write all of the abstracts line by line to a text file. This provides an easy and memory efficient format for the training loop below, but you can customize the input and data format to match your dataset so long as you update the huggingface Trainer interface below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn6diz3Cnn3R"
      },
      "source": [
        "outfile = open(\"abstracts.txt\", \"w\")\n",
        "for line in abstracts:\n",
        "  outfile.write(line.lower())\n",
        "  outfile.write(\"\\n\")\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6NuiBXMVHaf"
      },
      "source": [
        "## 4.2 Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hkk6baMG_ZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "8ed64e49-7af7-400c-e6bd-48140a5e2715"
      },
      "source": [
        "# Check that we have a GPU for training\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 24 19:49:28 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    60W / 149W |   8107MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkSDG9aV6HoT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc60dd5f-d37a-4c80-b9fb-96ea86b0f6ae"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFLfb_HY9085"
      },
      "source": [
        "The code below for training and evaluation is based heavily on the [\"how to train\" tutorial](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb) provided by huggingface, and demonstrates the use of their Trainer class and Pipeline class. The Trainer class is an alternative to writing your own training loop, and provides the same level of specification with much less code! The pipeline class is also a handy way to evaluate and test your model without having to manually code inputs, outputs, similarity comparisons, etc.\n",
        "\n",
        "(By the way, if you'd like to train a tokenizer and model from scratch the huggingface tutorial is a great resource!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1QzSi0Qbyw"
      },
      "source": [
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "# Create a LineByLineTextDataset interface for reading and tokenizing our text dataset\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=scibert_tokenizer,\n",
        "    file_path=\"abstracts.txt\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K2xR-R0_AQN"
      },
      "source": [
        "The DataCollatorForLanguageModeling creates batches out of our dataset and allows us to specify the MLM probability for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-RLbzsYQcC9"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=scibert_tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl38D7VH_e53"
      },
      "source": [
        "With the TrainingArguments class you can customize nearly every optimizer parameter, logging parameter, training loop parameter, etc. in one place. \n",
        "\n",
        "We'll train for just two epochs so we can quickly examine the results and check that the model has updated with continued training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63duaJUgeQyq"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(   \n",
        "    output_dir=\"./\",\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=5e-05, \n",
        "    num_train_epochs=1,\n",
        "    per_gpu_train_batch_size=32,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=scibert_maskedlm_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset= dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGs_ipsJ5sBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "b598157a04a74bcda1e52a240d06399c",
            "07eced1a774b438da179bed801638e48",
            "3b792004ab754fa5a02fa96f2fa16162",
            "0dec6cd1697a4f9ba4aba0ff3fd11093",
            "da7a1d7cce804e29906d3d4757b0b9f3",
            "a61bab9d35e247d6be4c77ae6adca33c",
            "80d1ded3744b42b2894ce1962b2c93a7",
            "8070eb7ac493436d9719a544b9ce41a2",
            "b6a41ae6af234de4b96bad725e0f6db5",
            "59655e281b8c4f3181c8e6c26015e202",
            "a607a55e6f7140ffa00053ee5b33bd91",
            "a1299c48e2df4a68b0d9470f2d7595a6",
            "dc36c38d37fe4bc2acf626e5284fc4d5",
            "25b6f0f2f3ad4adfbc76c0c97bd21b75",
            "96be4784928242cea94fbef3f43c605c",
            "0d3e656adef04df682a36d4afb9e3ee4"
          ]
        },
        "outputId": "b4ea46c2-b1f0-4e36-e3ad-1366a3db1b86"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b598157a04a74bcda1e52a240d06399c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6a41ae6af234de4b96bad725e0f6db5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=190.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "CPU times: user 2min 59s, sys: 1min 59s, total: 4min 58s\n",
            "Wall time: 4min 59s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=190, training_loss=1.4379032254219055)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G41NPEUXhpnB"
      },
      "source": [
        "# Save the model\n",
        "trainer.save_model(\"./covid_trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szt5K-WzVNc7"
      },
      "source": [
        "# S5. Examining our Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcSjXYAbsQh7"
      },
      "source": [
        "OK, let's take a look at the results of our trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0OasK6jpYg"
      },
      "source": [
        "# Load our saved model and check out our embeddings!\n",
        "from transformers import BertForMaskedLM\n",
        "trained_model = BertForMaskedLM.from_pretrained(\"./covid_trained\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeY6piflsZGT"
      },
      "source": [
        "## 5.1 Check Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjlqxWXzVSXf"
      },
      "source": [
        "Here's the original custom embedding we used for \"covid\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5alIWoYipEmS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f5d04896-1316-4ee7-fa1c-d4ec83ef2e78"
      },
      "source": [
        "mean_vector = mean_embedding.detach().numpy()\n",
        "\n",
        "plt.title(\"Custom Initialized Vector Before Training\")\n",
        "plt.hist(mean_vector, bins=50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKe_bL3fVWjh"
      },
      "source": [
        "And here's the same vector after our training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fst_21HppEhK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "49f3de17-a778-4225-a1df-b9926a069255"
      },
      "source": [
        "trained_vector = trained_model.get_input_embeddings().weight[-1].detach().numpy()\n",
        "\n",
        "plt.title(\"Custom Initialized Vector After Training\")\n",
        "plt.hist(trained_vector, bins=50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiWxxJ-jB86j"
      },
      "source": [
        "Great! Training has updated our new input embedding for \"covid\" and has updated the weights in the rest of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMcm6AMsseqk"
      },
      "source": [
        "## 5.2 Check Token Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2d1xCCbJkPM"
      },
      "source": [
        "Now let's compare the term \"covid\" on three versions of our model:\n",
        "\n",
        "\n",
        "\n",
        "1.   Original SciBERT with original SciBERT tokenizer\n",
        "2.   SciBERT with a custom embedding for \"covid\" with updated SciBERT tokenizer\n",
        "3.   SciBERT with a custom embedding for \"covid\" that has been trained on COVID-19 text with updated SciBERT tokenizer\n",
        "\n",
        "Let's load the original SciBERT and SciBERT tokenizer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh0grugQpEbJ"
      },
      "source": [
        "# Load the original SciBERT\n",
        "original_scibert_model = BertForMaskedLM.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "original_scibert_tokenizer = BertTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\", do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1wDGlE_V1LE"
      },
      "source": [
        "OK, now we have all three models loaded. \n",
        "\n",
        "We'll use the huggingface pipeline class to do a quick comparison of our embeddings. The \"fill-mask\" option lets us feed in a sentence with one token substituted with a mask token. The sentence gets tokenized, run through the model, and returns the top N most probable tokens to fill that embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kz0hg_jPOqJ"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Pipeline for Original SciBERT\n",
        "fill_mask_original_scibert = pipeline( \n",
        "    \"fill-mask\",\n",
        "    model=original_scibert_model,\n",
        "    tokenizer=original_scibert_tokenizer\n",
        ")\n",
        "\n",
        "# Pipeline for our custom \"covid\" embedding\n",
        "fill_mask_untrained_scibert_with_embedding = pipeline( \n",
        "    \"fill-mask\",\n",
        "    model=untrained_scibert_model_with_custom_embedding,\n",
        "    tokenizer=untrained_scibert_tokenizer_with_custom_embedding\n",
        ")\n",
        "\n",
        "# Pipeline for our trained model\n",
        "fill_mask_trained_scibert = pipeline( \n",
        "    \"fill-mask\",\n",
        "    model=trained_model,\n",
        "    tokenizer=untrained_scibert_tokenizer_with_custom_embedding\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z33DmLLWNrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "642eb4ef-afad-42e7-8012-f4476c49b0b3"
      },
      "source": [
        "# Check to see what the tokenizer's mask token is\n",
        "original_scibert_tokenizer.mask_token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[MASK]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_L6n2PRWVcj"
      },
      "source": [
        "OK! Now we can run the same sentence:\n",
        "\n",
        "**\"covid is a [MASK]\"**\n",
        "\n",
        "through our three models and see what it predicts as most likely on the other end!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUkboBYl8d-c"
      },
      "source": [
        "As we expected, the **Original SciBERT** doesn't have a good idea of what \"covid\" is at all, it's simply trying to make sense out of subtokens \"cov\" + \"##id\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHOSRAhKPOjc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "7ea8a537-5bb0-497f-d279-b72532106e4c"
      },
      "source": [
        "fill_mask_original_scibert(\"covid is a [MASK].\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.02992258034646511,\n",
              "  'sequence': '[CLS] covid is a constant. [SEP]',\n",
              "  'token': 2080},\n",
              " {'score': 0.015606057830154896,\n",
              "  'sequence': '[CLS] covid is a singleton. [SEP]',\n",
              "  'token': 23128},\n",
              " {'score': 0.015586997382342815,\n",
              "  'sequence': '[CLS] covid is a set. [SEP]',\n",
              "  'token': 610},\n",
              " {'score': 0.015000350773334503,\n",
              "  'sequence': '[CLS] covid is a proof. [SEP]',\n",
              "  'token': 2254},\n",
              " {'score': 0.014042431488633156,\n",
              "  'sequence': '[CLS] covid is a vector. [SEP]',\n",
              "  'token': 2069}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awGG4lcu8zjv"
      },
      "source": [
        "**SciBERT with a custom embedding for \"covid\"** does substantially better. As it turns out, our custom embedding of \"virus\" + \"respiratory\" does a pretty good first pass job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1cAuTnXSp2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "ad87f85c-416f-4d7b-de35-22b0b7e43280"
      },
      "source": [
        "fill_mask_untrained_scibert_with_embedding(\"covid is a [MASK].\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.24134275317192078,\n",
              "  'sequence': '[CLS] covid is a virus. [SEP]',\n",
              "  'token': 2930},\n",
              " {'score': 0.015654005110263824,\n",
              "  'sequence': '[CLS] covid is a disease. [SEP]',\n",
              "  'token': 1288},\n",
              " {'score': 0.00870219524949789,\n",
              "  'sequence': '[CLS] covid is a problem. [SEP]',\n",
              "  'token': 1167},\n",
              " {'score': 0.00780594814568758,\n",
              "  'sequence': '[CLS] covid is a name. [SEP]',\n",
              "  'token': 5147},\n",
              " {'score': 0.007489326875656843,\n",
              "  'sequence': '[CLS] covid is a pandemic. [SEP]',\n",
              "  'token': 26196}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1uOG5dT9NsS"
      },
      "source": [
        "Even with just one epoch of training on some abstracts, **Trained SciBERT** does an even better job. Notice here that the scores values are higher than they were for our custom embedding and the predicted tokens are more accurate; the uninformative \"name\" was a top 5 candidate for our custom embedding but for our trained model this is replaced with \"pathogen.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlBVkGEpSpwk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "aef48ba4-af2d-4919-b39e-20186536c1e8"
      },
      "source": [
        "fill_mask_trained_scibert(\"covid is a [MASK].\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.7195270657539368,\n",
              "  'sequence': '[CLS] covid is a pandemic. [SEP]',\n",
              "  'token': 26196},\n",
              " {'score': 0.08424169570207596,\n",
              "  'sequence': '[CLS] covid is a disease. [SEP]',\n",
              "  'token': 1288},\n",
              " {'score': 0.05053684487938881,\n",
              "  'sequence': '[CLS] covid is a virus. [SEP]',\n",
              "  'token': 2930},\n",
              " {'score': 0.0171565730124712,\n",
              "  'sequence': '[CLS] covid is a pathogen. [SEP]',\n",
              "  'token': 9293},\n",
              " {'score': 0.011855337768793106,\n",
              "  'sequence': '[CLS] covid is a threat. [SEP]',\n",
              "  'token': 8057}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccmUqAY_U6B"
      },
      "source": [
        "This indicates that the model we have trained is better suited as a COVID-19 language model or as the basis for fine-tuning.\n",
        "\n",
        "Similarly, we hope this tutorial will help you in customizing and improving a BERT-like language model for your specific downstream application. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGkVv2pduLv4"
      },
      "source": [
        "# Appendix - Additional Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT22fREDYHfS"
      },
      "source": [
        "\n",
        "While most of the literature is focused on fine-tuning against benchmarks, there isn't a great deal of research we've come across about continued pretraining or domain-specific fine-tuning despite its utility to industry-specific applications.\n",
        "\n",
        "One paper which does address this topic is \"[BERT on Stilts](https://arxiv.org/pdf/1811.01088.pdf)\" from a team at NYU--they measure the positive impact of an intermediate fine-tuning phase prior to the final benchmarked fine-tuning task.\n",
        "\n",
        "We'll continue to add more resources here as we come across them!\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}